{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "434b8102-09a5-4a59-8e51-d1914acdb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f2674b-955c-4e71-a62d-5b0087435f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' uncomment only for unpacking the downloaded data\\narchive_path = \"./aclImdb_v1.tar.gz\"\\nwith tarfile.open(archive_path, \"r:gz\") as tar:\\n    tar.extractall()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' uncomment only for unpacking the downloaded data\n",
    "archive_path = \"./aclImdb_v1.tar.gz\"\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aaf86bf-353b-449a-8fc1-55e0de5a1761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего текстов: 1981\n",
      "Пример текста: From: mss@netcom.com (Mark Singer)\n",
      "Subject: Re: Young Catchers\n",
      "Article-I.D.: netcom.mssC52qMx.768\n",
      "Organization: Netcom Online Communications Services (408-241-9760 login: guest)\n",
      "Lines: 86\n",
      "\n",
      "In article ...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "reviews = load_files('./aclImdb/train')\n",
    "texts = reviews.data\n",
    "labels = reviews.target\n",
    "'''\n",
    "categories = ['rec.sport.baseball', 'sci.space']\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "texts = newsgroups.data\n",
    "labels = newsgroups.target\n",
    "\n",
    "print(f\"Всего текстов: {len(texts)}\")\n",
    "print(f\"Пример текста: {texts[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684b7eda-9cff-4442-a87d-4bd32b6000e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448ebf3d-b8dc-4d41-9889-9bec1064860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "def build_vocab(texts, max_vocab_size=10000):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = simple_tokenizer(text)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    most_common = counter.most_common(max_vocab_size - 2)\n",
    "    vocab = {word: idx for idx, (word, _) in enumerate(most_common, start=2)}\n",
    "    vocab['<pad>'] = 0\n",
    "    vocab['<unk>'] = 1\n",
    "    \n",
    "    return vocab\n",
    "    \n",
    "def text_to_indices(text, vocab, max_len=50):\n",
    "    tokens = simple_tokenizer(text)\n",
    "    indices = [vocab.get(token, vocab['<unk>']) for token in tokens][:max_len]\n",
    "    # Добавляем паддинг если нужно\n",
    "    if len(indices) < max_len:\n",
    "        indices += [vocab['<pad>']] * (max_len - len(indices))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1307b47c-0e58-4a25-af07-c61b40fe2ea0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь: 1000 слов\n",
      "Пример словаря: {'the': 2, 'to': 3, 'of': 4, 'a': 5, 'and': 6, 'in': 7, 'i': 8, 'is': 9, 'that': 10, 'edu': 11, 'it': 12, 'for': 13, 's': 14, 'from': 15, 'on': 16, 'you': 17, 'be': 18, 'this': 19, 't': 20, 'have': 21, 'was': 22, 'are': 23, '0': 24, 'as': 25, 'with': 26}\n",
      "Пример данных:\n",
      "Текст 0: tensor([15,  1,  1,  1, 41,  1,  1, 33, 38, 87]) -> Метка: 1\n",
      "Текст 60: tensor([ 15, 456,   1,  41, 456,   1,  33,  38, 104, 297]) -> Метка: 0\n",
      "Текст 120: tensor([ 15,   1,   1,  11,  33,  38, 302,   1, 166,   1]) -> Метка: 1\n",
      "Текст 180: tensor([ 15,   1,   1, 948,  11, 200, 269,  33,  38,   1]) -> Метка: 0\n",
      "Текст 240: tensor([ 15,   1,   1,   1, 125, 358,   1,  33, 480,  13]) -> Метка: 0\n",
      "Текст 300: tensor([ 33,  32, 778, 311, 180, 170, 852,  15,   1, 100]) -> Метка: 1\n",
      "Текст 360: tensor([ 15,   1,   1,   1,  11,  20,   1,  33, 469, 223]) -> Метка: 1\n",
      "Текст 420: tensor([ 15,   1,   1, 182, 413,  11,   1,   1,  33,  38]) -> Метка: 1\n",
      "Текст 480: tensor([ 33,  32, 778, 361, 180, 914,   1,  15,   1, 100]) -> Метка: 1\n",
      "Текст 540: tensor([ 15, 514, 153, 231,  41, 236,  33,  38,   1,  16]) -> Метка: 1\n",
      "Текст 600: tensor([ 15,   1,   1,   1, 220,  11,   1,  33,  38, 659]) -> Метка: 0\n",
      "Текст 660: tensor([ 15,   1,   1,   1, 533,  11,   1, 521,  33,  38]) -> Метка: 0\n",
      "Текст 720: tensor([ 15,   1,   1,   1,   1,  11, 827, 318,   1,  33]) -> Метка: 1\n",
      "Текст 780: tensor([ 15, 788, 287,  41, 273, 773,  33,  38,   1,   1]) -> Метка: 0\n",
      "Текст 840: tensor([ 15,   1,   1,   1,   1,  11,   1, 262,   1,  33]) -> Метка: 0\n",
      "Текст 900: tensor([ 15,   1,   1, 100,   1, 125, 358,   1,  33,   1]) -> Метка: 1\n",
      "Текст 960: tensor([ 15,   1,   1,   1, 675,  11, 200, 610,   1,  33]) -> Метка: 0\n",
      "Текст 1020: tensor([ 15,   1,   1,   1,   1,  11, 827, 318,   1,  33]) -> Метка: 1\n",
      "Текст 1080: tensor([ 15,   1,   1,   1, 125,   1,   1,  33, 786, 310]) -> Метка: 0\n",
      "Текст 1140: tensor([ 15, 623,   1, 487, 439,  41, 692, 269, 623,   1]) -> Метка: 1\n",
      "Текст 1200: tensor([ 15, 134,   1, 182, 413,  11,  33,   1,   1,   1]) -> Метка: 1\n",
      "Текст 1260: tensor([ 15,   1,   1,  11, 358,   1,   2,   1,  33,  38]) -> Метка: 0\n",
      "Текст 1320: tensor([ 15,   1,   1, 100,   1,  11,   1,  12,  33,  38]) -> Метка: 0\n",
      "Текст 1380: tensor([ 15,   1,   1,   1,  11,  33,   1,  13, 295,  35]) -> Метка: 0\n",
      "Текст 1440: tensor([ 15, 874,   1, 628,  11, 200,  74, 874,  33,  38]) -> Метка: 1\n",
      "Текст 1500: tensor([ 15,   1,   1,   1,   1,  33,   1, 688,  61,   1]) -> Метка: 1\n",
      "Текст 1560: tensor([15,  1,  1,  1, 41,  1,  1, 33,  1,  6]) -> Метка: 1\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indices = text_to_indices(self.texts[idx], self.vocab, self.max_len)\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "vocab = build_vocab(train_texts, max_vocab_size=1000)\n",
    "print(f\"Словарь: {len(vocab)} слов\")\n",
    "print(\"Пример словаря:\", dict(list(vocab.items())[:25]))\n",
    "\n",
    "# Создаем dataset\n",
    "dataset = TextDataset(train_texts, train_labels, vocab, max_len=10)\n",
    "print(\"Пример данных:\")\n",
    "for i in range(0,len(dataset),60):\n",
    "    indices, label = dataset[i]\n",
    "    print(f\"Текст {i}: {indices} -> Метка: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3982c0a2-af3d-41f7-8507-b30535965b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_texts, train_labels, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = TextDataset(val_texts, val_labels, vocab)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327ab9c7-03bc-4261-8a2c-c6379abe3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embed)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5782b7-d8c9-409e-ae8e-3655849619d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_LSTM(vocab_size = len(vocab), embed_dim = 64, hidden_dim = 128, output_dim = 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "def train(num_epochs=10, patience = 3, train_loader=train_loader, val_loader=val_loader):\n",
    "    best_accuracy = 0\n",
    "    trigger_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        e_loss = 0.0\n",
    "        for x,y in tqdm(train_loader):\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outp = model(x)\n",
    "            loss = criterion(outp,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            e_loss+=loss.item()\n",
    "            \n",
    "        print(f'On {epoch+1}/{num_epochs} epoch loss = {e_loss/len(train_loader)}')\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0,0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (preds == y).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # callbacks\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            trigger_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "            }, \"best_RNN_trained.pth\")\n",
    "        else:\n",
    "            trigger_counter += 1\n",
    "            if trigger_counter >= patience:\n",
    "                break\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ec0ebd1-5a78-446b-a93b-8673b8a47491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 1/30 epoch loss = 0.6887738001346588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2/30 epoch loss = 0.5845504969358444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 3/30 epoch loss = 0.5007320874929428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 4/30 epoch loss = 0.4257336527109146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 5/30 epoch loss = 0.4331625375151634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 6/30 epoch loss = 0.4704365673661232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 7/30 epoch loss = 0.31757319226861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 8/30 epoch loss = 0.2346352843940258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 9/30 epoch loss = 0.17254639424383642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 10/30 epoch loss = 0.16666438408195972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 11/30 epoch loss = 0.13387531319633125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 12/30 epoch loss = 0.10358375798910856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 13/30 epoch loss = 0.06914439069107176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 14/30 epoch loss = 0.05469030514359474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 15/30 epoch loss = 0.05023158026859164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 16/30 epoch loss = 0.03316193690523505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 17/30 epoch loss = 0.024239648203365504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 18/30 epoch loss = 0.029908204567618668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 19/30 epoch loss = 0.023035225874045863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 20/30 epoch loss = 0.018607535033952446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 21/30 epoch loss = 0.036145967345219104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 22/30 epoch loss = 0.020241148504428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 23/30 epoch loss = 0.02931147494353354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 24/30 epoch loss = 0.03722226091194898\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bff17927-1c65-4a11-bcb0-8451297d959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.20654911838791\n",
      "374 397\n",
      "Accuracy on test: 94.20654911838791%\n"
     ]
    }
   ],
   "source": [
    "model = simple_LSTM(vocab_size = len(vocab), embed_dim = 64, hidden_dim = 128, output_dim = 2).to(device)\n",
    "checkpoint = torch.load(\"best_RNN_trained.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "accuracy = checkpoint['accuracy']\n",
    "print(accuracy)\n",
    "model.eval()\n",
    "correct, total = 0,0\n",
    "with torch.no_grad():\n",
    "    for x,y in val_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (preds == y).sum().item()\n",
    "\n",
    "print(correct, total)\n",
    "assert total == len(val_dataset)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf372dc-5b2d-40d0-b41e-b181cee8ca64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorEnv",
   "language": "python",
   "name": "tensorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
